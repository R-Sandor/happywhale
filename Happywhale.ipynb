{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd6ae9e-e1a9-43cd-8371-3c3292b81125",
   "metadata": {},
   "source": [
    "# Happywhale - CS795 Project 1\n",
    "***\n",
    "Old Dominion University\n",
    "\n",
    "2/26/2022\n",
    "#### Authors: Raphael J. Sandor, Xiangrui Xu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d468250-5e0e-4499-bba6-4212c43e6a51",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f01fec-43b7-4262-a7ce-31d97fafab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn\n",
    "import glob\n",
    "import json\n",
    "import keras\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import pickle\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_hub as tfhub\n",
    "import re\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from keras.optimizers import adam_v2\n",
    "from tensorflow.keras import backend as K\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f693e-5c1d-4dfc-9350-5044e7cc1137",
   "metadata": {},
   "source": [
    "# Global Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f14b1-dca0-451a-948c-8900e42a8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "'''\n",
    "    Use sample submission to gather which \n",
    "    images need predictions made \n",
    "'''\n",
    "test_df = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "total_image_df =  pd.concat([train_df['image'], test_df['image']])\n",
    "TRAIN_IMAGES_DIR = Path(\"./train_images\")\n",
    "TEST_IMAGES_DIR = Path(\"./test_images\")\n",
    "train_images = list(TRAIN_IMAGES_DIR.glob('./*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57903841-fc89-4fc5-85c1-53bf86060bcf",
   "metadata": {},
   "source": [
    "# Exploritory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602d7c8-7457-4a2c-9147-86f6ff0bf1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open(str(train_images[1000]))\n",
    "plt.figure(figsize = (10,10))\n",
    "imgplot = plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14681e57-f1fe-4bb7-a2c4-c7864689a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImgCnt = len(list(TRAIN_IMAGES_DIR.glob('*.jpg')))\n",
    "testImgCnt = len(list(TEST_IMAGES_DIR.glob('*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57472a7-2f16-457a-a1e5-1ddd2e374ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train image count: \" + str(trainImgCnt))\n",
    "print(\"Test image count: \" + str(testImgCnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413eab3e-cb02-4323-9120-a22c71ee6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb76253-3592-4223-98d4-7345164a3f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data in train\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266ed38a-67b2-449e-a7fa-ac2dc765e6d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unique Species "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb85b8b-13e6-4d9e-b1c8-354d650173da",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = train_df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89afb87d-ef07-4558-b3c6-97340a0dc457",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da58f557-d3d3-4d48-9e27-ce6cfd7c162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_species = pd.unique(species) # returns numpy.ndarray \n",
    "print(\"Unique Species\")\n",
    "print(\"-------------------\")\n",
    "print(*unique_species, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719eb393-2192-4ef7-bad5-288cf347f2b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Whales and Dolphins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f839d353-a3e4-4d9c-b9d8-9f0b8c2eced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the dataset includes some typo mistakes mistakes.\n",
    "train_df['species'].replace('bottlenose_dolpin', 'bottlenose_dolphin', inplace=True)\n",
    "train_df['species'].replace('kiler_whale', 'killer_whale', inplace=True)\n",
    "train_df['species'][(train_df['species'] ==\"pilot_whale\") | (train_df['species'] ==\"globis\" )]='short_finned_pilot_whale'\n",
    "\n",
    "whales = ['humpback_whale','beluga','minke_whale', 'fin_whale', 'blue_whale', 'gray_whale',\n",
    "          'southern_right_whale','sei_whale', 'cuviers_beaked_whale', 'brydes_whale']\n",
    "\n",
    "dolphins = ['melon_headed_whale','false_killer_whale', 'bottlenose_dolphin', 'common_dolphin', \n",
    "            'dusky_dolphin', 'killer_whale', 'long_finned_pilot_whale', 'spinner_dolphin', \n",
    "            'spotted_dolphin','commersons_dolphin', 'white_sided_dolphin', 'short_finned_pilot_whale',\n",
    "            'rough_toothed_dolphin', 'pantropic_spotted_dolphin', 'frasiers_dolphin', 'pygmy_killer_whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ad39a-2d4f-4107-9aa7-8849025fbcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "whale_df = train_df[train_df['species'].str.contains('|'.join(whales))]\n",
    "dolphin_df = train_df[train_df['species'].str.contains('|'.join(dolphins))]\n",
    "print(\"Total species after :\",len(train_df.species.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc470122-e255-44a6-8ef9-acebc87d8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(whale_df.head())\n",
    "print(\"---------------------------------------------\")\n",
    "print(dolphin_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff793f9d-2715-40da-8975-06362d74425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets check speiceis in visually\n",
    "# Nikhil Jothi Prakash \n",
    "# Works cited: https://www.kaggle.com/nikhiljothiprakash/happy-whale-and-dolphin\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "plt.barh(train_df[\"species\"].value_counts().sort_values(ascending=True).index,train_df[\"species\"].value_counts().sort_values(ascending=True),tick_label = train_df[\"species\"].value_counts().sort_values(ascending=True).index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e8d19-f335-4d39-829b-eb81dc9f79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Species of whales: \" + str(len(whales)))\n",
    "print(\"Species of dolphins: \" + str(len(dolphins)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028391ec-4930-4ec0-b8c9-c3b211ef89e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of whales: \" + str(whale_df.shape[0]))\n",
    "print(\"Number of dolphins: \" + str(dolphin_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f384705-2c22-445c-9bd5-d321af874b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets classify on whales.\n",
    "train_df['isWhale'] = train_df.species.isin(whale_df.species).astype(int)\n",
    "train_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af9ef9-f47c-496b-ad40-9a096c049d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35fcc6-8b07-487f-be05-c9d0f7438658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed from \n",
    "# https://www.kaggle.com/samir95/species-classification\n",
    "_, dev, _ , _ = train_test_split(train_df, train_df['isWhale'], test_size=0.1)\n",
    "\n",
    "dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0258ae22-c582-4f8a-9bd1-4f62d420cab0",
   "metadata": {},
   "source": [
    "# CNN Dataset\n",
    "<ol>\n",
    "  <li>Load the data.</li>\n",
    "  <li>Resize images to be normalized</li>\n",
    "</ol>\n",
    "<i> If I had more time and knowledge I would use the TFRecords from the next step </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e739dd-6b96-47c0-8125-37ec84d93c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "from fastai.basics import *\n",
    "from fastai.data.all import *\n",
    "\n",
    "from fastai.vision.core import *\n",
    "import fastbook\n",
    "fastbook.setup_book() \n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "dev['imagePath'] = dev['image'].apply(lambda f: TRAIN_IMAGES_DIR/f)\n",
    "train_df['imagePath'] = train_df['image'].apply(lambda f: TRAIN_IMAGES_DIR/f)\n",
    "\n",
    "dblock = DataBlock(blocks=(ImageBlock, CategoryBlock), \n",
    "                   get_x=ColReader('imagePath'),\n",
    "                   get_y=lambda r: r['isWhale'],\n",
    "                   splitter=RandomSplitter(seed=42),\n",
    "                   item_tfms=Resize(460),\n",
    "                   batch_tfms=aug_transforms(size=224))\n",
    "#dblock.summary(dev)\n",
    "dsets = dblock.datasets(dev)\n",
    "dls = dblock.dataloaders(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faecf6f-28fc-4098-88a7-625018ee9204",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TFRecords For Faster Performance \n",
    "##### Creating TFRecords will provide better performance than manual image manipulations according to Keras.\n",
    "https://keras.io/examples/keras_recipes/creating_tfrecords/\n",
    "\n",
    "<i> We'll use this when we do individual predicitions <i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e94b3b-1225-4a2e-bbb7-0c2c7ddfef29",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba90dc-dcc9-40e6-adee-a16ee5b2c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works cited:\n",
    "# https://www.kaggle.com/nikhiljothiprakash/happy-whale-and-dolphin/notebook\n",
    "concat_df = pd.concat([train_df['image'], test_df['image']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1146684-487c-4473-994d-5b68ad395d8c",
   "metadata": {},
   "source": [
    "### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769826c8-98a3-4ffe-a250-2c25f60430a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create dict for species\n",
    "spid_dict = dict((a,b) for b,a in enumerate(train_df.species.unique()))\n",
    "spid_dict_inverse={(c,d) for d,c in spid_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea74814f-3bec-4c72-96f7-864fac4b98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name_to_image_id = dict((image_name, index) for index, image_name in enumerate(concat_df.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162972c-6964-41c8-8b24-19f6ad984936",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dict = dict((image,index) for index,image in enumerate(concat_df.unique()))\n",
    "img_dict_inverse = {ind:img for img,ind in img_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d2993-a9b7-40f0-9d18-86b59c520270",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets create dict for individual id \n",
    "id_dict = dict((a,b) for b,a in enumerate(train_df.individual_id.unique()))\n",
    "id_dict_inverse={(c,d) for d,c in id_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c665f-dcd8-49d8-9367-064ef3e310f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"label\"]=[id_dict[i] for i in train_df.individual_id]\n",
    "train_df[\"image_id\"]=[img_dict[i] for i in train_df['image']]\n",
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7d9c4-d0ca-4e55-921c-410cb496215e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper Functions\n",
    "Borrowed from Keras:https://keras.io/examples/keras_recipes/creating_tfrecords/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fb910f-4293-4ce6-b07d-1992e00a5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(value).numpy()])\n",
    "    )\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "\n",
    "def int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def float_feature_list(value):\n",
    "    \"\"\"Returns a list of float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50596095-bc2a-48ee-b005-9720c1aee244",
   "metadata": {},
   "source": [
    "## Create TFRecords\n",
    "Faster image manipulation in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7fe5f-8b26-43b9-9d86-98611943a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed example of making records from \n",
    "# Gaurav Chopra\n",
    "# https://www.kaggle.com/gauravchopracg/understanding-tfrecord-format\n",
    "# Create a function to apply entire process to each element of dataset.\n",
    "# process the two images into 'tf.Example' messages.\n",
    "def create_example(image_id, image, label):\n",
    "  \"\"\"\n",
    "  Creates a tf.Example message ready to be written to a file.\n",
    "  \"\"\"\n",
    "  # Create a dictionary mapping the feature name to the tf.Example-compatible\n",
    "  # data type.\n",
    "  feature = {\n",
    "    \"image_id\": int64_feature(image_id),\n",
    "    \"image\": image_feature(image),\n",
    "    \"label\": int64_feature(label)\n",
    "  }  \n",
    "  # Create a Features message using tf.train.Example.\n",
    "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "\n",
    "def  write_records():\n",
    "  #Write the `tf.Example` observations to the file.\n",
    "  with tf.io.TFRecordWriter(train_records) as writer:\n",
    "    for i, row in new.iterrows():\n",
    "      image = tf.io.decode_jpeg(tf.io.read_file(str(row['imagePath'])))\n",
    "    \n",
    "      # storing all the features in the tf.Example message.\n",
    "      tf_example = create_example(row['image_id'], image, row['label'])\n",
    "      # write the example messages to a file named images.tfrecords\n",
    "      writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b06089-32c8-4c81-b965-d86c78557c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a filename to store preprocessed image data:\n",
    "train_records = 'trainImages.tfrecords'\n",
    "test_records = 'testImages.tfrecords'\n",
    "new = train_df[['image_id','imagePath', 'label']].copy()\n",
    "\n",
    "if not os.path.exists(\"trainImages.tfrecords\"):\n",
    "  write_records()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d2fd7-db9a-4098-9774-b8e97749fdde",
   "metadata": {},
   "source": [
    "# Start CNN Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f805d-31b5-440d-999f-a820d8bc2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=20)\n",
    "learn = cnn_learner(dls, resnet34, metrics=[accuracy, error_rate])\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c863b64-275e-49df-b6e8-3a11a103a7e5",
   "metadata": {},
   "source": [
    "# Fine Tune and Improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f35fa-0fe2-42d3-abe6-435184fdd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(2, base_lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f9851-9e08-4cfc-81ee-6aca0b80574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze()\n",
    "learn.fit_one_cycle(3, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec8582-6903-4f67-aed0-2602a4999d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5776dc-3d9e-4822-83a6-98a5d32db28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(6, lr_max=slice(1e-6, 1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180309b-b5fc-4312-9311-57834a5836ee",
   "metadata": {},
   "source": [
    "# Classification based on Individual \n",
    "#### using research by Andre C. Ferreira as a starting point on this venture\n",
    "##### https://github.com/AndreCFerreira/Bird_individualID/blob/master/Train_CNN/TRAIN_CNN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071cf40a-df5e-47ad-a719-c38b6ac94d59",
   "metadata": {},
   "source": [
    "Lets explore how many individuals we are working with in this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa5806b-54fa-4611-ae11-292d77eb5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d2e67-74f9-4b7e-a9de-04c1f1ff5976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(data,target,num_splits):\n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    data[\"kfold\"] = -1\n",
    "    \n",
    "    # the next step is to randomize the rows of the data\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # calculate number of bins by Sturge's rule\n",
    "    # I take the floor of the value, you can also\n",
    "    # just round it\n",
    "    num_bins = int(np.floor(1 + np.log2(len(data))))\n",
    "    \n",
    "    # bin targets\n",
    "    data.loc[:, \"bins\"] = pd.cut(\n",
    "        data[target], bins=num_bins, labels=False\n",
    "    )\n",
    "    \n",
    "    # initiate the kfold class from model_selection module\n",
    "    kf = model_selection.StratifiedKFold(n_splits=num_splits)\n",
    "    \n",
    "    # fill the new kfold column\n",
    "    # note that, instead of targets, we use bins!\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n",
    "        data.loc[v_, 'kfold'] = f\n",
    "    \n",
    "    # drop the bins column\n",
    "    data = data.drop(\"bins\", axis=1)\n",
    "\n",
    "    # return dataframe with folds\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318131d-c743-4df5-a49d-e5aaa5df84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image to array\n",
    "def decode_image(image_raw):\n",
    "    image = tf.image.decode_jpeg(image_raw, channels=3)\n",
    "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a90e0d-cc68-4bbc-9e81-d0b965f15686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(raw_image_dataset):\n",
    "    feature_description = {\n",
    "        \"image_id\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image_raw\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    parsed_image_dataset = tf.io.parse_single_example(raw_image_dataset, feature_description)\n",
    "    image_id = tf.cast(parsed_image_dataset['image_id'], tf.int32)\n",
    "    image = decode_image(parsed_image_dataset['image_raw'])\n",
    "    label = tf.cast(parsed_image_dataset['label'], tf.int32)\n",
    "    \n",
    "    return image_id, image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce594d3d-ea7a-4247-b47d-01e69d8080b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '.'\n",
    "EXPERIMENT = 0\n",
    "run_ts = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "print(run_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11401ae-8ec0-4807-8218-72cdbd171153",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "\n",
    "class config:\n",
    "    \n",
    "    \n",
    "    SEED = 42\n",
    "    FOLD_TO_RUN = 0\n",
    "    FOLDS = 5\n",
    "    DEBUG = False\n",
    "    EVALUATE = True\n",
    "    RESUME = False\n",
    "    RESUME_EPOCH = None\n",
    "    \n",
    "    \n",
    "    ### Dataset\n",
    "    BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "    IMAGE_SIZE = 512\n",
    "    N_CLASSES = 15587\n",
    "    \n",
    "    ### Model\n",
    "    model_type = 'effnetv1'  \n",
    "    EFF_NET = 5\n",
    "    EFF_NETV2 = 's-21k-ft1k'\n",
    "    FREEZE_BATCH_NORM = False\n",
    "    head = 'arcface' \n",
    "    EPOCHS = 20\n",
    "    LR = 0.001\n",
    "    message='baseline'\n",
    "    \n",
    "    ### Augmentations\n",
    "    CUTOUT = False\n",
    "    \n",
    "    ### Save-Directory\n",
    "    save_dir = save_dir\n",
    "    \n",
    "    ### Inference\n",
    "    KNN = 50\n",
    "    \n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n",
    "         for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "def is_interactive():\n",
    "    return 'runtime'    in get_ipython().config.IPKernelApp.connection_file\n",
    "IS_INTERACTIVE = is_interactive()\n",
    "print(IS_INTERACTIVE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6ff24-02c1-4842-bd10-723208d7894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = None\n",
    "if config.model_type == 'effnetv1':\n",
    "    MODEL_NAME = f'effnetv1_b{config.EFF_NET}'\n",
    "elif config.model_type == 'effnetv2':\n",
    "    MODEL_NAME = f'effnetv2_{config.EFF_NETV2}'\n",
    "\n",
    "config.MODEL_NAME = MODEL_NAME\n",
    "print(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d08dc3-c7a5-41d3-990b-2fe5845f681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.save_dir+'/config.json', 'w') as fp:\n",
    "    json.dump({x:dict(config.__dict__)[x] for x in dict(config.__dict__) if not x.startswith('_')}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7a8ce-6ba2-4f33-8c2e-62e85df144ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_PATH = KaggleDatasets().get_gcs_path('happywhale-tfrecords-v1')\n",
    "    \n",
    "train_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/happywhale-2022-train*.tfrec')))\n",
    "test_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/happywhale-2022-test*.tfrec')))\n",
    "print(GCS_PATH)\n",
    "print(len(train_files),len(test_files),count_data_items(train_files),count_data_items(test_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21831e09-28cc-4b0c-9050-d81c9f329fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da32ee-2f27-4a54-8709-9c67e82d0b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008308c-b5c0-4f22-83b0-b4a9a9ca788e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
